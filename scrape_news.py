# -*- coding: utf-8 -*-
"""scrape_news.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JzK_m-tKBPGlHtRGtQgqSM9CmmI5bjYA
"""

import pandas as pd
from datetime import datetime, timedelta
import requests
import time
from bs4 import BeautifulSoup
import logging

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# NewsAPI key
NEWS_API_KEY = "e52f8d2ac2544e599051722e18b746d1"

# Function to fetch crypto news headlines using NewsAPI
def fetch_news_api(date, query="bitcoin OR ethereum OR solana OR cryptocurrency", max_headlines=3):
    url = "https://newsapi.org/v2/everything"
    params = {
        "q": query,
        "from": date.strftime("%Y-%m-%d"),
        "to": date.strftime("%Y-%m-%d"),
        "language": "en",
        "sortBy": "relevancy",
        "apiKey": NEWS_API_KEY
    }
    try:
        response = requests.get(url, params=params)
        response.raise_for_status()
        articles = response.json().get("articles", [])
        headlines = [article["title"] for article in articles if article["title"] and any(term in article["title"].lower() for term in ["bitcoin", "ethereum", "solana", "crypto"])]
        # Ensure unique headlines and limit to max_headlines
        headlines = list(dict.fromkeys(headlines))[:max_headlines]
        # Pad with placeholders if fewer than max_headlines
        while len(headlines) < max_headlines:
            headlines.append(f"No crypto headline for {date.strftime('%m/%d/%Y')} #{len(headlines)+1}")
        return headlines
    except requests.RequestException as e:
        logging.error(f"Error fetching crypto news for {date}: {e}")
        return [f"Error fetching crypto headline for {date.strftime('%m/%d/%Y')} #{i+1}" for i in range(max_headlines)]

# Function to scrape crypto news headlines from CoinDesk
def scrape_coindesk(date, max_headlines=3):
    url = "https://www.coindesk.com"
    try:
        response = requests.get(url)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")
        # Target article headlines with crypto-related content
        headlines = []
        for tag in soup.find_all(["h1", "h2", "h3"]):
            text = tag.get_text().strip()
            if text and any(term in text.lower() for term in ["bitcoin", "ethereum", "solana", "crypto", "blockchain"]):
                headlines.append(text)
        headlines = list(dict.fromkeys(headlines))[:max_headlines]
        # Pad with placeholders if needed
        while len(headlines) < max_headlines:
            headlines.append(f"No crypto headline for {date.strftime('%m/%d/%Y')} #{len(headlines)+1}")
        return headlines
    except requests.RequestException as e:
        logging.error(f"Error scraping CoinDesk for {date}: {e}")
        return [f"Error scraping crypto headline for {date.strftime('%m/%d/%Y')} #{i+1}" for i in range(max_headlines)]

# Function to generate news.csv
def generate_news_csv(start_date, end_date, output_file="news.csv"):
    date_range = pd.date_range(start=start_date, end=end_date, freq="D")
    news_data = []

    for date in date_range:
        logging.info(f"Fetching crypto news for {date.strftime('%m/%d/%Y')}")
        # Try NewsAPI first
        headlines = fetch_news_api(date)
        # Fallback to CoinDesk if NewsAPI fails or returns insufficient headlines
        if any("Error" in h for h in headlines) or len(headlines) < 3 or any("No crypto headline" in h for h in headlines):
            logging.warning(f"NewsAPI failed for {date}, trying CoinDesk")
            headlines = scrape_coindesk(date)

        # Store headlines
        news_data.append({
            "Date": date.strftime("%m/%d/%Y"),
            "Headline_1": headlines[0],
            "Headline_2": headlines[1],
            "Headline_3": headlines[2]
        })
        # Respect API rate limits
        time.sleep(1)

    # Create DataFrame and save to CSV
    news_df = pd.DataFrame(news_data)
    news_df.to_csv(output_file, index=False)
    logging.info(f"Saved crypto news data to {output_file}")

# Main function
def main():
    # Define date range (March 25, 2025 to April 18, 2025)
    start_date = datetime(2025, 3, 25)
    end_date = datetime(2025, 4, 18)
    output_file = "news.csv"

    # Generate news.csv
    generate_news_csv(start_date, end_date, output_file)

if __name__ == "__main__":
    main()